{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO4EUvT+upIvB/5MCbxHEHh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Melyns/collab/blob/main/flux_to_gguf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oP9yJQdoNhBu",
        "outputId": "c5b98f5e-9241-45f5-d60b-ae5c5343811a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'llama.cpp'...\n",
            "remote: Enumerating objects: 32644, done.\u001b[K\n",
            "remote: Total 32644 (delta 0), reused 0 (delta 0), pack-reused 32644 (from 1)\u001b[K\n",
            "Receiving objects: 100% (32644/32644), 57.51 MiB | 7.74 MiB/s, done.\n",
            "Resolving deltas: 100% (23447/23447), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ggerganov/llama.cpp.git\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xHTEDNOP140",
        "outputId": "fdf2c8ba-384f-450b-d741-d9d7f1bd8673"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "llama.cpp  sample_data\n"
          ]
        }
      ]
    },
    {
      "source": [
        "!pip install huggingface-cli\n",
        "!huggingface-cli login"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmBTDCOqQTw3",
        "outputId": "c647455a-8dcf-457f-a539-833b3a078045"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement huggingface-cli (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for huggingface-cli\u001b[0m\u001b[31m\n",
            "\u001b[0m\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: fineGrained).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "# Define the repository and file details\n",
        "repo_id = \"black-forest-labs/FLUX.1-dev\"\n",
        "filename = \"flux1-dev.safetensors\"\n",
        "cache_dir = \"/content/hf\"  # Update this to the path where you want to save the file\n",
        "\n",
        "# Download the file\n",
        "file_path = hf_hub_download(repo_id=repo_id, filename=filename, cache_dir=cache_dir)\n",
        "\n",
        "print(f\"File downloaded to: {file_path}\")\n"
      ],
      "metadata": {
        "id": "CNcin43bRIQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/hf"
      ],
      "metadata": {
        "id": "0v7gWt6mUDt_"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yh2ApDuUTiFh",
        "outputId": "385c1e45-fafc-47e8-f424-1b81532490c9"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "flux1-dev.safetensors  llama.cpp  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "yA0gu6OqUvYP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama.cpp/gguf-py\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7nMdftPV_3n",
        "outputId": "f8ac5080-3b55-4d76-9f74-1e890eb11dbd"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing ./llama.cpp/gguf-py\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from gguf==0.10.0) (1.26.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from gguf==0.10.0) (6.0.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from gguf==0.10.0) (4.66.5)\n",
            "Building wheels for collected packages: gguf\n",
            "  Building wheel for gguf (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gguf: filename=gguf-0.10.0-py3-none-any.whl size=71584 sha256=706089fba756a06913227841b4a6c8398360fa991569fd974e663a92b224e33f\n",
            "  Stored in directory: /root/.cache/pip/wheels/75/42/13/ff5427daa7a8a54a9bbcfafc10a0cd0cb13eae7952fb878270\n",
            "Successfully built gguf\n",
            "Installing collected packages: gguf\n",
            "Successfully installed gguf-0.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/city96/ComfyUI-GGUF/\n"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "le5ZITHhduZd",
        "outputId": "0b5e1a20-babe-4171-dab4-b1ea333c3cd7"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ComfyUI-GGUF'...\n",
            "remote: Enumerating objects: 204, done.\u001b[K\n",
            "remote: Counting objects:   0% (1/146)\u001b[K\rremote: Counting objects:   1% (2/146)\u001b[K\rremote: Counting objects:   2% (3/146)\u001b[K\rremote: Counting objects:   3% (5/146)\u001b[K\rremote: Counting objects:   4% (6/146)\u001b[K\rremote: Counting objects:   5% (8/146)\u001b[K\rremote: Counting objects:   6% (9/146)\u001b[K\rremote: Counting objects:   7% (11/146)\u001b[K\rremote: Counting objects:   8% (12/146)\u001b[K\rremote: Counting objects:   9% (14/146)\u001b[K\rremote: Counting objects:  10% (15/146)\u001b[K\rremote: Counting objects:  11% (17/146)\u001b[K\rremote: Counting objects:  12% (18/146)\u001b[K\rremote: Counting objects:  13% (19/146)\u001b[K\rremote: Counting objects:  14% (21/146)\u001b[K\rremote: Counting objects:  15% (22/146)\u001b[K\rremote: Counting objects:  16% (24/146)\u001b[K\rremote: Counting objects:  17% (25/146)\u001b[K\rremote: Counting objects:  18% (27/146)\u001b[K\rremote: Counting objects:  19% (28/146)\u001b[K\rremote: Counting objects:  20% (30/146)\u001b[K\rremote: Counting objects:  21% (31/146)\u001b[K\rremote: Counting objects:  22% (33/146)\u001b[K\rremote: Counting objects:  23% (34/146)\u001b[K\rremote: Counting objects:  24% (36/146)\u001b[K\rremote: Counting objects:  25% (37/146)\u001b[K\rremote: Counting objects:  26% (38/146)\u001b[K\rremote: Counting objects:  27% (40/146)\u001b[K\rremote: Counting objects:  28% (41/146)\u001b[K\rremote: Counting objects:  29% (43/146)\u001b[K\rremote: Counting objects:  30% (44/146)\u001b[K\rremote: Counting objects:  31% (46/146)\u001b[K\rremote: Counting objects:  32% (47/146)\u001b[K\rremote: Counting objects:  33% (49/146)\u001b[K\rremote: Counting objects:  34% (50/146)\u001b[K\rremote: Counting objects:  35% (52/146)\u001b[K\rremote: Counting objects:  36% (53/146)\u001b[K\rremote: Counting objects:  37% (55/146)\u001b[K\rremote: Counting objects:  38% (56/146)\u001b[K\rremote: Counting objects:  39% (57/146)\u001b[K\rremote: Counting objects:  40% (59/146)\u001b[K\rremote: Counting objects:  41% (60/146)\u001b[K\rremote: Counting objects:  42% (62/146)\u001b[K\rremote: Counting objects:  43% (63/146)\u001b[K\rremote: Counting objects:  44% (65/146)\u001b[K\rremote: Counting objects:  45% (66/146)\u001b[K\rremote: Counting objects:  46% (68/146)\u001b[K\rremote: Counting objects:  47% (69/146)\u001b[K\rremote: Counting objects:  48% (71/146)\u001b[K\rremote: Counting objects:  49% (72/146)\u001b[K\rremote: Counting objects:  50% (73/146)\u001b[K\rremote: Counting objects:  51% (75/146)\u001b[K\rremote: Counting objects:  52% (76/146)\u001b[K\rremote: Counting objects:  53% (78/146)\u001b[K\rremote: Counting objects:  54% (79/146)\u001b[K\rremote: Counting objects:  55% (81/146)\u001b[K\rremote: Counting objects:  56% (82/146)\u001b[K\rremote: Counting objects:  57% (84/146)\u001b[K\rremote: Counting objects:  58% (85/146)\u001b[K\rremote: Counting objects:  59% (87/146)\u001b[K\rremote: Counting objects:  60% (88/146)\u001b[K\rremote: Counting objects:  61% (90/146)\u001b[K\rremote: Counting objects:  62% (91/146)\u001b[K\rremote: Counting objects:  63% (92/146)\u001b[K\rremote: Counting objects:  64% (94/146)\u001b[K\rremote: Counting objects:  65% (95/146)\u001b[K\rremote: Counting objects:  66% (97/146)\u001b[K\rremote: Counting objects:  67% (98/146)\u001b[K\rremote: Counting objects:  68% (100/146)\u001b[K\rremote: Counting objects:  69% (101/146)\u001b[K\rremote: Counting objects:  70% (103/146)\u001b[K\rremote: Counting objects:  71% (104/146)\u001b[K\rremote: Counting objects:  72% (106/146)\u001b[K\rremote: Counting objects:  73% (107/146)\u001b[K\rremote: Counting objects:  74% (109/146)\u001b[K\rremote: Counting objects:  75% (110/146)\u001b[K\rremote: Counting objects:  76% (111/146)\u001b[K\rremote: Counting objects:  77% (113/146)\u001b[K\rremote: Counting objects:  78% (114/146)\u001b[K\rremote: Counting objects:  79% (116/146)\u001b[K\rremote: Counting objects:  80% (117/146)\u001b[K\rremote: Counting objects:  81% (119/146)\u001b[K\rremote: Counting objects:  82% (120/146)\u001b[K\rremote: Counting objects:  83% (122/146)\u001b[K\rremote: Counting objects:  84% (123/146)\u001b[K\rremote: Counting objects:  85% (125/146)\u001b[K\rremote: Counting objects:  86% (126/146)\u001b[K\rremote: Counting objects:  87% (128/146)\u001b[K\rremote: Counting objects:  88% (129/146)\u001b[K\rremote: Counting objects:  89% (130/146)\u001b[K\rremote: Counting objects:  90% (132/146)\u001b[K\rremote: Counting objects:  91% (133/146)\u001b[K\rremote: Counting objects:  92% (135/146)\u001b[K\rremote: Counting objects:  93% (136/146)\u001b[K\rremote: Counting objects:  94% (138/146)\u001b[K\rremote: Counting objects:  95% (139/146)\u001b[K\rremote: Counting objects:  96% (141/146)\u001b[K\rremote: Counting objects:  97% (142/146)\u001b[K\rremote: Counting objects:  98% (144/146)\u001b[K\rremote: Counting objects:  99% (145/146)\u001b[K\rremote: Counting objects: 100% (146/146)\u001b[K\rremote: Counting objects: 100% (146/146), done.\u001b[K\n",
            "remote: Compressing objects:   1% (1/82)\u001b[K\rremote: Compressing objects:   2% (2/82)\u001b[K\rremote: Compressing objects:   3% (3/82)\u001b[K\rremote: Compressing objects:   4% (4/82)\u001b[K\rremote: Compressing objects:   6% (5/82)\u001b[K\rremote: Compressing objects:   7% (6/82)\u001b[K\rremote: Compressing objects:   8% (7/82)\u001b[K\rremote: Compressing objects:   9% (8/82)\u001b[K\rremote: Compressing objects:  10% (9/82)\u001b[K\rremote: Compressing objects:  12% (10/82)\u001b[K\rremote: Compressing objects:  13% (11/82)\u001b[K\rremote: Compressing objects:  14% (12/82)\u001b[K\rremote: Compressing objects:  15% (13/82)\u001b[K\rremote: Compressing objects:  17% (14/82)\u001b[K\rremote: Compressing objects:  18% (15/82)\u001b[K\rremote: Compressing objects:  19% (16/82)\u001b[K\rremote: Compressing objects:  20% (17/82)\u001b[K\rremote: Compressing objects:  21% (18/82)\u001b[K\rremote: Compressing objects:  23% (19/82)\u001b[K\rremote: Compressing objects:  24% (20/82)\u001b[K\rremote: Compressing objects:  25% (21/82)\u001b[K\rremote: Compressing objects:  26% (22/82)\u001b[K\rremote: Compressing objects:  28% (23/82)\u001b[K\rremote: Compressing objects:  29% (24/82)\u001b[K\rremote: Compressing objects:  30% (25/82)\u001b[K\rremote: Compressing objects:  31% (26/82)\u001b[K\rremote: Compressing objects:  32% (27/82)\u001b[K\rremote: Compressing objects:  34% (28/82)\u001b[K\rremote: Compressing objects:  35% (29/82)\u001b[K\rremote: Compressing objects:  36% (30/82)\u001b[K\rremote: Compressing objects:  37% (31/82)\u001b[K\rremote: Compressing objects:  39% (32/82)\u001b[K\rremote: Compressing objects:  40% (33/82)\u001b[K\rremote: Compressing objects:  41% (34/82)\u001b[K\rremote: Compressing objects:  42% (35/82)\u001b[K\rremote: Compressing objects:  43% (36/82)\u001b[K\rremote: Compressing objects:  45% (37/82)\u001b[K\rremote: Compressing objects:  46% (38/82)\u001b[K\rremote: Compressing objects:  47% (39/82)\u001b[K\rremote: Compressing objects:  48% (40/82)\u001b[K\rremote: Compressing objects:  50% (41/82)\u001b[K\rremote: Compressing objects:  51% (42/82)\u001b[K\rremote: Compressing objects:  52% (43/82)\u001b[K\rremote: Compressing objects:  53% (44/82)\u001b[K\rremote: Compressing objects:  54% (45/82)\u001b[K\rremote: Compressing objects:  56% (46/82)\u001b[K\rremote: Compressing objects:  57% (47/82)\u001b[K\rremote: Compressing objects:  58% (48/82)\u001b[K\rremote: Compressing objects:  59% (49/82)\u001b[K\rremote: Compressing objects:  60% (50/82)\u001b[K\rremote: Compressing objects:  62% (51/82)\u001b[K\rremote: Compressing objects:  63% (52/82)\u001b[K\rremote: Compressing objects:  64% (53/82)\u001b[K\rremote: Compressing objects:  65% (54/82)\u001b[K\rremote: Compressing objects:  67% (55/82)\u001b[K\rremote: Compressing objects:  68% (56/82)\u001b[K\rremote: Compressing objects:  69% (57/82)\u001b[K\rremote: Compressing objects:  70% (58/82)\u001b[K\rremote: Compressing objects:  71% (59/82)\u001b[K\rremote: Compressing objects:  73% (60/82)\u001b[K\rremote: Compressing objects:  74% (61/82)\u001b[K\rremote: Compressing objects:  75% (62/82)\u001b[K\rremote: Compressing objects:  76% (63/82)\u001b[K\rremote: Compressing objects:  78% (64/82)\u001b[K\rremote: Compressing objects:  79% (65/82)\u001b[K\rremote: Compressing objects:  80% (66/82)\u001b[K\rremote: Compressing objects:  81% (67/82)\u001b[K\rremote: Compressing objects:  82% (68/82)\u001b[K\rremote: Compressing objects:  84% (69/82)\u001b[K\rremote: Compressing objects:  85% (70/82)\u001b[K\rremote: Compressing objects:  86% (71/82)\u001b[K\rremote: Compressing objects:  87% (72/82)\u001b[K\rremote: Compressing objects:  89% (73/82)\u001b[K\rremote: Compressing objects:  90% (74/82)\u001b[K\rremote: Compressing objects:  91% (75/82)\u001b[K\rremote: Compressing objects:  92% (76/82)\u001b[K\rremote: Compressing objects:  93% (77/82)\u001b[K\rremote: Compressing objects:  95% (78/82)\u001b[K\rremote: Compressing objects:  96% (79/82)\u001b[K\rremote: Compressing objects:  97% (80/82)\u001b[K\rremote: Compressing objects:  98% (81/82)\u001b[K\rremote: Compressing objects: 100% (82/82)\u001b[K\rremote: Compressing objects: 100% (82/82), done.\u001b[K\n",
            "Receiving objects:   0% (1/204)\rReceiving objects:   1% (3/204)\rReceiving objects:   2% (5/204)\rReceiving objects:   3% (7/204)\rReceiving objects:   4% (9/204)\rReceiving objects:   5% (11/204)\rReceiving objects:   6% (13/204)\rReceiving objects:   7% (15/204)\rReceiving objects:   8% (17/204)\rReceiving objects:   9% (19/204)\rReceiving objects:  10% (21/204)\rReceiving objects:  11% (23/204)\rReceiving objects:  12% (25/204)\rReceiving objects:  13% (27/204)\rReceiving objects:  14% (29/204)\rReceiving objects:  15% (31/204)\rReceiving objects:  16% (33/204)\rReceiving objects:  17% (35/204)\rReceiving objects:  18% (37/204)\rReceiving objects:  19% (39/204)\rReceiving objects:  20% (41/204)\rReceiving objects:  21% (43/204)\rReceiving objects:  22% (45/204)\rReceiving objects:  23% (47/204)\rReceiving objects:  24% (49/204)\rReceiving objects:  25% (51/204)\rReceiving objects:  26% (54/204)\rReceiving objects:  27% (56/204)\rReceiving objects:  28% (58/204)\rReceiving objects:  29% (60/204)\rReceiving objects:  30% (62/204)\rReceiving objects:  31% (64/204)\rReceiving objects:  32% (66/204)\rReceiving objects:  33% (68/204)\rReceiving objects:  34% (70/204)\rremote: Total 204 (delta 105), reused 93 (delta 64), pack-reused 58 (from 1)\u001b[K\n",
            "Receiving objects:  35% (72/204)\rReceiving objects:  36% (74/204)\rReceiving objects:  37% (76/204)\rReceiving objects:  38% (78/204)\rReceiving objects:  39% (80/204)\rReceiving objects:  40% (82/204)\rReceiving objects:  41% (84/204)\rReceiving objects:  42% (86/204)\rReceiving objects:  43% (88/204)\rReceiving objects:  44% (90/204)\rReceiving objects:  45% (92/204)\rReceiving objects:  46% (94/204)\rReceiving objects:  47% (96/204)\rReceiving objects:  48% (98/204)\rReceiving objects:  49% (100/204)\rReceiving objects:  50% (102/204)\rReceiving objects:  51% (105/204)\rReceiving objects:  52% (107/204)\rReceiving objects:  53% (109/204)\rReceiving objects:  54% (111/204)\rReceiving objects:  55% (113/204)\rReceiving objects:  56% (115/204)\rReceiving objects:  57% (117/204)\rReceiving objects:  58% (119/204)\rReceiving objects:  59% (121/204)\rReceiving objects:  60% (123/204)\rReceiving objects:  61% (125/204)\rReceiving objects:  62% (127/204)\rReceiving objects:  63% (129/204)\rReceiving objects:  64% (131/204)\rReceiving objects:  65% (133/204)\rReceiving objects:  66% (135/204)\rReceiving objects:  67% (137/204)\rReceiving objects:  68% (139/204)\rReceiving objects:  69% (141/204)\rReceiving objects:  70% (143/204)\rReceiving objects:  71% (145/204)\rReceiving objects:  72% (147/204)\rReceiving objects:  73% (149/204)\rReceiving objects:  74% (151/204)\rReceiving objects:  75% (153/204)\rReceiving objects:  76% (156/204)\rReceiving objects:  77% (158/204)\rReceiving objects:  78% (160/204)\rReceiving objects:  79% (162/204)\rReceiving objects:  80% (164/204)\rReceiving objects:  81% (166/204)\rReceiving objects:  82% (168/204)\rReceiving objects:  83% (170/204)\rReceiving objects:  84% (172/204)\rReceiving objects:  85% (174/204)\rReceiving objects:  86% (176/204)\rReceiving objects:  87% (178/204)\rReceiving objects:  88% (180/204)\rReceiving objects:  89% (182/204)\rReceiving objects:  90% (184/204)\rReceiving objects:  91% (186/204)\rReceiving objects:  92% (188/204)\rReceiving objects:  93% (190/204)\rReceiving objects:  94% (192/204)\rReceiving objects:  95% (194/204)\rReceiving objects:  96% (196/204)\rReceiving objects:  97% (198/204)\rReceiving objects:  98% (200/204)\rReceiving objects:  99% (202/204)\rReceiving objects: 100% (204/204)\rReceiving objects: 100% (204/204), 70.92 KiB | 8.86 MiB/s, done.\n",
            "Resolving deltas:   0% (0/119)\rResolving deltas:   1% (2/119)\rResolving deltas:   2% (3/119)\rResolving deltas:   3% (4/119)\rResolving deltas:   4% (5/119)\rResolving deltas:   5% (6/119)\rResolving deltas:   6% (8/119)\rResolving deltas:   7% (9/119)\rResolving deltas:   8% (10/119)\rResolving deltas:   9% (11/119)\rResolving deltas:  10% (12/119)\rResolving deltas:  11% (14/119)\rResolving deltas:  12% (15/119)\rResolving deltas:  13% (16/119)\rResolving deltas:  14% (17/119)\rResolving deltas:  15% (18/119)\rResolving deltas:  16% (20/119)\rResolving deltas:  17% (21/119)\rResolving deltas:  18% (22/119)\rResolving deltas:  19% (23/119)\rResolving deltas:  21% (25/119)\rResolving deltas:  22% (27/119)\rResolving deltas:  23% (28/119)\rResolving deltas:  24% (29/119)\rResolving deltas:  25% (30/119)\rResolving deltas:  26% (31/119)\rResolving deltas:  27% (33/119)\rResolving deltas:  28% (34/119)\rResolving deltas:  29% (35/119)\rResolving deltas:  30% (36/119)\rResolving deltas:  31% (37/119)\rResolving deltas:  32% (39/119)\rResolving deltas:  33% (40/119)\rResolving deltas:  34% (41/119)\rResolving deltas:  35% (42/119)\rResolving deltas:  36% (43/119)\rResolving deltas:  37% (45/119)\rResolving deltas:  38% (46/119)\rResolving deltas:  39% (47/119)\rResolving deltas:  40% (48/119)\rResolving deltas:  41% (49/119)\rResolving deltas:  42% (50/119)\rResolving deltas:  43% (52/119)\rResolving deltas:  44% (53/119)\rResolving deltas:  45% (54/119)\rResolving deltas:  46% (55/119)\rResolving deltas:  47% (56/119)\rResolving deltas:  48% (58/119)\rResolving deltas:  49% (59/119)\rResolving deltas:  50% (60/119)\rResolving deltas:  51% (61/119)\rResolving deltas:  52% (62/119)\rResolving deltas:  53% (64/119)\rResolving deltas:  54% (65/119)\rResolving deltas:  55% (66/119)\rResolving deltas:  56% (67/119)\rResolving deltas:  57% (68/119)\rResolving deltas:  58% (70/119)\rResolving deltas:  59% (71/119)\rResolving deltas:  60% (72/119)\rResolving deltas:  61% (73/119)\rResolving deltas:  62% (74/119)\rResolving deltas:  63% (75/119)\rResolving deltas:  64% (77/119)\rResolving deltas:  65% (78/119)\rResolving deltas:  66% (79/119)\rResolving deltas:  67% (80/119)\rResolving deltas:  68% (81/119)\rResolving deltas:  69% (83/119)\rResolving deltas:  70% (84/119)\rResolving deltas:  71% (85/119)\rResolving deltas:  72% (86/119)\rResolving deltas:  73% (87/119)\rResolving deltas:  74% (89/119)\rResolving deltas:  75% (90/119)\rResolving deltas:  76% (91/119)\rResolving deltas:  77% (92/119)\rResolving deltas:  78% (93/119)\rResolving deltas:  79% (95/119)\rResolving deltas:  80% (96/119)\rResolving deltas:  81% (97/119)\rResolving deltas:  82% (98/119)\rResolving deltas:  83% (99/119)\rResolving deltas:  84% (100/119)\rResolving deltas:  85% (102/119)\rResolving deltas:  86% (103/119)\rResolving deltas:  87% (104/119)\rResolving deltas:  88% (105/119)\rResolving deltas:  89% (106/119)\rResolving deltas:  90% (108/119)\rResolving deltas:  91% (109/119)\rResolving deltas:  92% (110/119)\rResolving deltas:  93% (111/119)\rResolving deltas:  94% (112/119)\rResolving deltas:  95% (114/119)\rResolving deltas:  96% (115/119)\rResolving deltas:  97% (116/119)\rResolving deltas:  98% (117/119)\rResolving deltas:  99% (118/119)\rResolving deltas: 100% (119/119)\rResolving deltas: 100% (119/119), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCUB-sHEpRNH",
        "outputId": "b7a37d77-4e2e-41ac-9a90-8a61f7b18267"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r /content/llama.cpp/requirements.txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TktcHvTZpglZ",
        "outputId": "2706bde1-8994-4e3b-fb0e-049dcae4def2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cpu, https://download.pytorch.org/whl/cpu, https://download.pytorch.org/whl/cpu, https://download.pytorch.org/whl/cpu\n",
            "Requirement already satisfied: numpy~=1.26.4 in /usr/local/lib/python3.10/dist-packages (from -r /content/llama.cpp/./requirements/requirements-convert_legacy_llama.txt (line 1)) (1.26.4)\n",
            "Collecting sentencepiece~=0.2.0 (from -r /content/llama.cpp/./requirements/requirements-convert_legacy_llama.txt (line 2))\n",
            "  Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.40.1 in /usr/local/lib/python3.10/dist-packages (from -r /content/llama.cpp/./requirements/requirements-convert_legacy_llama.txt (line 3)) (4.42.4)\n",
            "Requirement already satisfied: gguf>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/llama.cpp/./requirements/requirements-convert_legacy_llama.txt (line 4)) (0.10.0)\n",
            "Collecting protobuf<5.0.0,>=4.21.0 (from -r /content/llama.cpp/./requirements/requirements-convert_legacy_llama.txt (line 5))\n",
            "  Downloading protobuf-4.25.4-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Collecting torch~=2.2.1 (from -r /content/llama.cpp/./requirements/requirements-convert_hf_to_gguf.txt (line 3))\n",
            "  Downloading https://download.pytorch.org/whl/cpu/torch-2.2.2%2Bcpu-cp310-cp310-linux_x86_64.whl (186.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m186.8/186.8 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.40.1->-r /content/llama.cpp/./requirements/requirements-convert_legacy_llama.txt (line 3)) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.40.1->-r /content/llama.cpp/./requirements/requirements-convert_legacy_llama.txt (line 3)) (0.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.40.1->-r /content/llama.cpp/./requirements/requirements-convert_legacy_llama.txt (line 3)) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.40.1->-r /content/llama.cpp/./requirements/requirements-convert_legacy_llama.txt (line 3)) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.40.1->-r /content/llama.cpp/./requirements/requirements-convert_legacy_llama.txt (line 3)) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.40.1->-r /content/llama.cpp/./requirements/requirements-convert_legacy_llama.txt (line 3)) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.40.1->-r /content/llama.cpp/./requirements/requirements-convert_legacy_llama.txt (line 3)) (0.4.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.40.1->-r /content/llama.cpp/./requirements/requirements-convert_legacy_llama.txt (line 3)) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.40.1->-r /content/llama.cpp/./requirements/requirements-convert_legacy_llama.txt (line 3)) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch~=2.2.1->-r /content/llama.cpp/./requirements/requirements-convert_hf_to_gguf.txt (line 3)) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch~=2.2.1->-r /content/llama.cpp/./requirements/requirements-convert_hf_to_gguf.txt (line 3)) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch~=2.2.1->-r /content/llama.cpp/./requirements/requirements-convert_hf_to_gguf.txt (line 3)) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch~=2.2.1->-r /content/llama.cpp/./requirements/requirements-convert_hf_to_gguf.txt (line 3)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch~=2.2.1->-r /content/llama.cpp/./requirements/requirements-convert_hf_to_gguf.txt (line 3)) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch~=2.2.1->-r /content/llama.cpp/./requirements/requirements-convert_hf_to_gguf.txt (line 3)) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers<5.0.0,>=4.40.1->-r /content/llama.cpp/./requirements/requirements-convert_legacy_llama.txt (line 3)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers<5.0.0,>=4.40.1->-r /content/llama.cpp/./requirements/requirements-convert_legacy_llama.txt (line 3)) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers<5.0.0,>=4.40.1->-r /content/llama.cpp/./requirements/requirements-convert_legacy_llama.txt (line 3)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers<5.0.0,>=4.40.1->-r /content/llama.cpp/./requirements/requirements-convert_legacy_llama.txt (line 3)) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch~=2.2.1->-r /content/llama.cpp/./requirements/requirements-convert_hf_to_gguf.txt (line 3)) (1.3.0)\n",
            "Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.25.4-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece, protobuf, torch\n",
            "  Attempting uninstall: sentencepiece\n",
            "    Found existing installation: sentencepiece 0.1.99\n",
            "    Uninstalling sentencepiece-0.1.99:\n",
            "      Successfully uninstalled sentencepiece-0.1.99\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.3.1+cu121\n",
            "    Uninstalling torch-2.3.1+cu121:\n",
            "      Successfully uninstalled torch-2.3.1+cu121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/ComfyUI-GGUF/tools/convert.py --src /content/flux1-dev.safetensors --dst /content/flux1-dev.gguf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KDIVKUvdVJ4",
        "outputId": "55a0c6d2-60d4-4041-f9c3-36946cd01d32"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: convert.py [-h] --src SRC [--dst DST]\n",
            "convert.py: error: No input provided!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/ComfyUI-GGUF/tools/convert.py -h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rv4xIjTcnY16",
        "outputId": "6ccf8ad9-6a6e-4d22-c394-9d84f4e28397"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: convert.py [-h] --src SRC [--dst DST]\n",
            "\n",
            "Generate F16 GGUF files from single UNET\n",
            "\n",
            "options:\n",
            "  -h, --help  show this help message and exit\n",
            "  --src SRC   Source model ckpt file.\n",
            "  --dst DST   Output unet gguf file.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ggerganov/llama.cpp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INoFj84FgbAk",
        "outputId": "9d0d9894-b5c3-4c8e-f70a-0ff127a28da1"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'llama.cpp'...\n",
            "remote: Enumerating objects: 32644, done.\u001b[K\n",
            "remote: Total 32644 (delta 0), reused 0 (delta 0), pack-reused 32644 (from 1)\u001b[K\n",
            "Receiving objects: 100% (32644/32644), 57.81 MiB | 16.01 MiB/s, done.\n",
            "Resolving deltas: 100% (23451/23451), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/llama.cpp /content/lama\n"
      ],
      "metadata": {
        "id": "CbfMpj4ogj98"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install lama/gguf-py\n"
      ],
      "metadata": {
        "id": "rJ5dKxPHgr7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/city96/ComfyUI-GGUF"
      ],
      "metadata": {
        "id": "NNnchGgDgzTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dx2BZrR-g1xI",
        "outputId": "9207e163-3ff8-4bec-f9b7-c65d6038dbc8"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ComfyUI-GGUF  flux1-dev.safetensors  lama  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/ComfyUI-GGUF/tools/convert.py --src /content/flux1-dev.safetensors\n"
      ],
      "metadata": {
        "id": "VP7-9Uk6g35j"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}